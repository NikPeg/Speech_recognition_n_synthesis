# Лекция 2: Подготовка данных для обучения ASR

## Подготовка данных

### Манифест данных для NeMo

Формат JSON-строк с полями:
- `audio_filepath` — путь к аудиофайлу
- `duration` — длительность в секундах
- `text` — транскрипция текста

**Пример:**
```json
{"audio_filepath": "/path/to/file.wav", "duration": 1.696625, "text": "джой хватит"}
```

## Токенизация

**Токенизация** — первый шаг в обработке текстовых данных, преобразование текста в токены для анализа.

### Типы токенизаторов

#### Byte Pair Encoding (BPE)

Алгоритм субсловной токенизации, итеративно объединяющий наиболее частые пары символов.

**Алгоритм:**
1. Инициализировать словарь отдельными символами
2. Подсчитать частоту всех соседних пар
3. Объединить наиболее частую пару и добавить в словарь
4. Повторять до достижения нужного размера словаря

#### Unigram Language Model

Алгоритм, моделирующий токенизацию как вероятностный процесс.

**Алгоритм:**
1. Инициализировать словарь большим набором возможных токенов
2. Обучить униграммную языковую модель для оценки вероятностей токенов
3. Итеративно удалять токены с наименьшей вероятностью

## Модели ASR

**Ресурсы:**
- [Open ASR Leaderboard](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard) — сравнение моделей
- [NeMo ASR Models](https://docs.nvidia.com/nemo-framework/user-guide/25.07/nemotoolkit/asr/models.html)
- [NeMo ASR Configs](https://docs.nvidia.com/nemo-framework/user-guide/25.07/nemotoolkit/asr/configs.html)

### Лучшие модели (по WER):
- `nvidia/canary-qwen-2.5b` — WER: 5.63
- `ibm-granite/granite-speech-3.3-8b` — WER: 5.74
- `ibm-granite/granite-speech-3.3-2b` — WER: 6.0

