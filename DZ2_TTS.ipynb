{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Домашнее задание №2: Синтез речи\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install git+https://github.com/OHF-Voice/piper1-gpl.git\n",
        "%pip install tensorboard\n",
        "%pip install onnx\n",
        "%pip install onnxruntime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Импорты\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Подготовка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = \"/share/audio_data/sova/ytub/raid/nanosemantics/nextcloud/sova_done\"\n",
        "OUTPUT_DIR = \"./tts_data\"\n",
        "NATAHA_DIR = \"/tf/nspeganov/nataha\"\n",
        "TRAIN_DIR = os.path.join(NATAHA_DIR, \"train\")\n",
        "VAL_DIR = os.path.join(NATAHA_DIR, \"valid\")\n",
        "TEST_DIR = os.path.join(OUTPUT_DIR, \"test\")\n",
        "\n",
        "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
        "os.makedirs(VAL_DIR, exist_ok=True)\n",
        "os.makedirs(TEST_DIR, exist_ok=True)\n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "MIN_DURATION = 0.5\n",
        "MAX_DURATION = 10.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_text(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def trim_silence(audio, sr, threshold_db=-40):\n",
        "    try:\n",
        "        trimmed, _ = librosa.effects.trim(audio, top_db=abs(threshold_db))\n",
        "        return trimmed\n",
        "    except:\n",
        "        return audio\n",
        "\n",
        "def load_audio_info(audio_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=None)\n",
        "        duration = len(y) / sr\n",
        "        return duration, sr, y\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при загрузке {audio_path}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "def prepare_tts_dataset(base_path, parts=['part_0', 'part_1', 'part_2'], max_files=None, trim_silence_audio=True):\n",
        "    import time\n",
        "    dataset = []\n",
        "    audio_extensions = ['.wav', '.mp3', '.flac', '.ogg']\n",
        "    audio_files = []\n",
        "    \n",
        "    print(\"Поиск аудиофайлов...\")\n",
        "    search_start = time.time()\n",
        "    \n",
        "    for part in parts:\n",
        "        part_path = os.path.join(base_path, part)\n",
        "        if not os.path.exists(part_path):\n",
        "            print(f\"Предупреждение: часть {part} не найдена\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nОбработка {part}...\")\n",
        "        part_start = time.time()\n",
        "        \n",
        "        # Сначала собираем все поддиректории для оценки прогресса\n",
        "        all_dirs = []\n",
        "        print(\"  Сканирование структуры директорий...\")\n",
        "        for root, dirs, files in os.walk(part_path):\n",
        "            all_dirs.append(root)\n",
        "        \n",
        "        print(f\"  Найдено {len(all_dirs)} поддиректорий\")\n",
        "        \n",
        "        # Поиск файлов с прогресс-баром\n",
        "        part_files = []\n",
        "        ext_counts = {ext: 0 for ext in audio_extensions}\n",
        "        \n",
        "        pbar_search = tqdm(all_dirs, desc=f\"Поиск в {part}\", unit=\"дир\", ncols=100, leave=False)\n",
        "        for root in pbar_search:\n",
        "            try:\n",
        "                for file in os.listdir(root):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    if os.path.isfile(file_path):\n",
        "                        file_ext = os.path.splitext(file)[1].lower()\n",
        "                        if file_ext in audio_extensions:\n",
        "                            part_files.append(file_path)\n",
        "                            ext_counts[file_ext] += 1\n",
        "                            pbar_search.set_postfix({\n",
        "                                'найдено': len(part_files),\n",
        "                                'wav': ext_counts['.wav'],\n",
        "                                'mp3': ext_counts['.mp3']\n",
        "                            })\n",
        "            except (PermissionError, OSError) as e:\n",
        "                continue\n",
        "        \n",
        "        audio_files.extend(part_files)\n",
        "        part_time = time.time() - part_start\n",
        "        print(f\"  {part}: найдено {len(part_files)} файлов за {part_time:.1f}с ({part_time/60:.1f} мин)\")\n",
        "        for ext, count in ext_counts.items():\n",
        "            if count > 0:\n",
        "                print(f\"    {ext}: {count} файлов\")\n",
        "    \n",
        "    search_time = time.time() - search_start\n",
        "    \n",
        "    if max_files and len(audio_files) > max_files:\n",
        "        print(f\"\\nОграничение: было {len(audio_files)} файлов, оставляем {max_files}\")\n",
        "        audio_files = audio_files[:max_files]\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Поиск завершен: найдено {len(audio_files)} аудиофайлов\")\n",
        "    print(f\"Время поиска: {search_time:.1f}с ({search_time/60:.1f} мин)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    print(\"Начинаю обработку файлов...\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    processed = 0\n",
        "    skipped_no_text = 0\n",
        "    skipped_duration = 0\n",
        "    skipped_trim = 0\n",
        "    \n",
        "    pbar = tqdm(audio_files, desc=\"Подготовка данных\", unit=\"файл\", ncols=100)\n",
        "    for audio_path in pbar:\n",
        "        duration, sr, y = load_audio_info(audio_path)\n",
        "        if duration is None:\n",
        "            continue\n",
        "        \n",
        "        if duration < MIN_DURATION or duration > MAX_DURATION:\n",
        "            skipped_duration += 1\n",
        "            continue\n",
        "        \n",
        "        text_path = audio_path.rsplit('.', 1)[0] + '.txt'\n",
        "        if not os.path.exists(text_path):\n",
        "            skipped_no_text += 1\n",
        "            continue\n",
        "        \n",
        "        with open(text_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read().strip()\n",
        "        \n",
        "        text = normalize_text(text)\n",
        "        \n",
        "        if len(text) > 0:\n",
        "            resampled_audio = librosa.resample(y, orig_sr=sr, target_sr=SAMPLE_RATE) if sr != SAMPLE_RATE else y\n",
        "            \n",
        "            if trim_silence_audio:\n",
        "                resampled_audio = trim_silence(resampled_audio, SAMPLE_RATE)\n",
        "                if len(resampled_audio) < SAMPLE_RATE * MIN_DURATION:\n",
        "                    skipped_trim += 1\n",
        "                    continue\n",
        "            \n",
        "            dataset.append({\n",
        "                \"audio\": resampled_audio,\n",
        "                \"text\": text,\n",
        "                \"duration\": len(resampled_audio) / SAMPLE_RATE,\n",
        "                \"path\": audio_path\n",
        "            })\n",
        "            processed += 1\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        pbar.set_postfix({\n",
        "            'Обработано': processed,\n",
        "            'Пропущено': skipped_no_text + skipped_duration + skipped_trim,\n",
        "            'Время': f\"{elapsed:.1f}с\"\n",
        "        })\n",
        "    \n",
        "    elapsed_total = time.time() - start_time\n",
        "    print(f\"\\nПодготовка завершена!\")\n",
        "    print(f\"  Обработано записей: {len(dataset)}\")\n",
        "    print(f\"  Пропущено (нет текста): {skipped_no_text}\")\n",
        "    print(f\"  Пропущено (длительность): {skipped_duration}\")\n",
        "    print(f\"  Пропущено (после обрезки): {skipped_trim}\")\n",
        "    print(f\"  Время обработки: {elapsed_total:.1f} секунд ({elapsed_total/60:.1f} минут)\")\n",
        "    print(f\"  Скорость: {len(audio_files)/elapsed_total:.1f} файлов/сек\")\n",
        "    \n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"НАЧАЛО ПОДГОТОВКИ ДАННЫХ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dataset = prepare_tts_dataset(DATA_PATH, parts=['part_0', 'part_1', 'part_2'])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"РАЗДЕЛЕНИЕ ДАННЫХ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"Перемешивание данных...\")\n",
        "random.shuffle(dataset)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "\n",
        "train_data = dataset[:train_size]\n",
        "val_data = dataset[train_size:train_size + val_size]\n",
        "test_data = dataset[train_size + val_size:]\n",
        "\n",
        "print(f\"\\nРазделение данных:\")\n",
        "print(f\"  Train: {len(train_data)} записей ({100*len(train_data)/len(dataset):.1f}%)\")\n",
        "print(f\"  Val: {len(val_data)} записей ({100*len(val_data)/len(dataset):.1f}%)\")\n",
        "print(f\"  Test: {len(test_data)} записей ({100*len(test_data)/len(dataset):.1f}%)\")\n",
        "\n",
        "print(\"\\nВычисление статистики по длительности...\")\n",
        "durations = [item['duration'] for item in tqdm(dataset, desc=\"Обработка длительностей\", unit=\"запись\", leave=False)]\n",
        "\n",
        "print(f\"\\nСтатистика по длительности:\")\n",
        "print(f\"  Минимум: {min(durations):.2f} сек\")\n",
        "print(f\"  Максимум: {max(durations):.2f} сек\")\n",
        "print(f\"  Среднее: {np.mean(durations):.2f} сек\")\n",
        "print(f\"  Медиана: {np.median(durations):.2f} сек\")\n",
        "print(f\"  Общая длительность: {sum(durations)/3600:.2f} часов\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ПОДГОТОВКА ДАННЫХ ЗАВЕРШЕНА\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Сохранение подготовленных данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_dataset_csv(data, output_dir, csv_path):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    with open(csv_path, 'w', encoding='utf-8') as f:\n",
        "        for i, item in enumerate(tqdm(data, desc=\"Сохранение\", unit=\"файл\")):\n",
        "            audio_filename = f\"{i:06d}.wav\"\n",
        "            audio_path = os.path.join(output_dir, audio_filename)\n",
        "            \n",
        "            sf.write(audio_path, item['audio'], SAMPLE_RATE)\n",
        "            \n",
        "            text = item['text'].replace('|', ' ').replace('\\n', ' ').strip()\n",
        "            f.write(f\"{audio_filename}|{text}\\n\")\n",
        "    \n",
        "    print(f\"CSV сохранен: {csv_path}\")\n",
        "    return csv_path\n",
        "\n",
        "train_csv = save_dataset_csv(train_data, TRAIN_DIR, os.path.join(NATAHA_DIR, \"train.csv\"))\n",
        "val_csv = save_dataset_csv(val_data, VAL_DIR, os.path.join(NATAHA_DIR, \"valid.csv\"))\n",
        "\n",
        "print(f\"\\nCSV файлы сохранены:\")\n",
        "print(f\"  Train: {train_csv}\")\n",
        "print(f\"  Val: {val_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Создание конфигурационного файла\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_path = os.path.join(OUTPUT_DIR, \"nata_config.json\")\n",
        "\n",
        "config = {\n",
        "    \"audio\": {\n",
        "        \"sample_rate\": SAMPLE_RATE\n",
        "    },\n",
        "    \"espeak\": {\n",
        "        \"voice\": \"ru\"\n",
        "    },\n",
        "    \"phoneme_type\": \"espeak\",\n",
        "    \"num_symbols\": 256,\n",
        "    \"num_speakers\": 1,\n",
        "    \"inference\": {\n",
        "        \"noise_scale\": 0.667,\n",
        "        \"length_scale\": 1.0,\n",
        "        \"noise_w\": 0.8\n",
        "    },\n",
        "    \"hop_length\": 256,\n",
        "    \"piper_version\": \"1.3.0\"\n",
        "}\n",
        "\n",
        "with open(config_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Конфигурация сохранена: {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка базового чекпоинта\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Загрузка базового чекпоинта\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "base_checkpoint_url = \"https://huggingface.co/datasets/rhasspy/piper-checkpoints/resolve/main/ru/ru_RU/ruslan/medium/epoch=2436-step=1724372.ckpt\"\n",
        "base_checkpoint_path = os.path.join(CHECKPOINT_DIR, \"epoch=2436-step=1724372.ckpt\")\n",
        "\n",
        "if not os.path.exists(base_checkpoint_path):\n",
        "    print(\"Загрузка базового чекпоинта...\")\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(base_checkpoint_url, base_checkpoint_path)\n",
        "    print(f\"Чекпоинт загружен: {base_checkpoint_path}\")\n",
        "else:\n",
        "    print(f\"Чекпоинт уже существует: {base_checkpoint_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "cache_dir = os.path.join(OUTPUT_DIR, \"nata_cache\")\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "log_dir = os.path.join(OUTPUT_DIR, \"lightning_logs\")\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "print(\"Запуск обучения...\")\n",
        "print(\"Команда обучения будет выполнена в следующей ячейке\")\n",
        "\n",
        "train_cmd = [\n",
        "    \"python3\", \"-m\", \"piper.train\", \"fit\",\n",
        "    \"--data.voice_name\", \"nata\",\n",
        "    \"--data.csv_path\", train_csv,\n",
        "    \"--data.audio_dir\", TRAIN_DIR,\n",
        "    \"--model.sample_rate\", str(SAMPLE_RATE),\n",
        "    \"--data.espeak_voice\", \"ru\",\n",
        "    \"--data.cache_dir\", cache_dir,\n",
        "    \"--data.config_path\", config_path,\n",
        "    \"--data.batch_size\", \"16\",\n",
        "    \"--ckpt_path\", base_checkpoint_path\n",
        "]\n",
        "\n",
        "print(\" \".join(train_cmd))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "cache_dir = os.path.join(OUTPUT_DIR, \"nata_cache\")\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "log_dir = os.path.join(OUTPUT_DIR, \"lightning_logs\")\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "print(\"Настройка команды обучения...\")\n",
        "\n",
        "train_cmd = [\n",
        "    \"python3\", \"-m\", \"piper.train\", \"fit\",\n",
        "    \"--data.voice_name\", \"nata\",\n",
        "    \"--data.csv_path\", train_csv,\n",
        "    \"--data.audio_dir\", TRAIN_DIR,\n",
        "    \"--model.sample_rate\", str(SAMPLE_RATE),\n",
        "    \"--data.espeak_voice\", \"ru\",\n",
        "    \"--data.cache_dir\", cache_dir,\n",
        "    \"--data.config_path\", config_path,\n",
        "    \"--data.batch_size\", \"16\",\n",
        "    \"--ckpt_path\", base_checkpoint_path\n",
        "]\n",
        "\n",
        "print(\"Команда обучения:\")\n",
        "print(\" \".join(train_cmd))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = subprocess.run(train_cmd, cwd=OUTPUT_DIR)\n",
        "print(f\"Обучение завершено с кодом: {result.returncode}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Визуализация метрик из TensorBoard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_metrics(log_dir):\n",
        "    try:\n",
        "        from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "        \n",
        "        version_dirs = [d for d in os.listdir(log_dir) if os.path.isdir(os.path.join(log_dir, d))]\n",
        "        if not version_dirs:\n",
        "            print(\"Логи TensorBoard не найдены\")\n",
        "            return\n",
        "        \n",
        "        latest_version = max(version_dirs)\n",
        "        event_dir = os.path.join(log_dir, latest_version)\n",
        "        \n",
        "        event_acc = EventAccumulator(event_dir)\n",
        "        event_acc.Reload()\n",
        "        \n",
        "        scalar_tags = event_acc.Tags()['scalars']\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        if 'train/loss' in scalar_tags or 'train_loss' in scalar_tags:\n",
        "            tag = 'train/loss' if 'train/loss' in scalar_tags else 'train_loss'\n",
        "            train_loss = event_acc.Scalars(tag)\n",
        "            axes[0, 0].plot([s.step for s in train_loss], [s.value for s in train_loss], label='Train Loss')\n",
        "        \n",
        "        if 'val/loss' in scalar_tags or 'val_loss' in scalar_tags:\n",
        "            tag = 'val/loss' if 'val/loss' in scalar_tags else 'val_loss'\n",
        "            val_loss = event_acc.Scalars(tag)\n",
        "            axes[0, 0].plot([s.step for s in val_loss], [s.value for s in val_loss], label='Val Loss')\n",
        "        \n",
        "        axes[0, 0].set_xlabel('Step')\n",
        "        axes[0, 0].set_ylabel('Loss')\n",
        "        axes[0, 0].set_title('Training and Validation Loss')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True)\n",
        "        \n",
        "        if 'train/mel_loss' in scalar_tags or 'train_mel_loss' in scalar_tags:\n",
        "            tag = 'train/mel_loss' if 'train/mel_loss' in scalar_tags else 'train_mel_loss'\n",
        "            train_mel = event_acc.Scalars(tag)\n",
        "            axes[0, 1].plot([s.step for s in train_mel], [s.value for s in train_mel], label='Train Mel Loss')\n",
        "        \n",
        "        if 'val/mel_loss' in scalar_tags or 'val_mel_loss' in scalar_tags:\n",
        "            tag = 'val/mel_loss' if 'val/mel_loss' in scalar_tags else 'val_mel_loss'\n",
        "            val_mel = event_acc.Scalars(tag)\n",
        "            axes[0, 1].plot([s.step for s in val_mel], [s.value for s in val_mel], label='Val Mel Loss')\n",
        "        \n",
        "        axes[0, 1].set_xlabel('Step')\n",
        "        axes[0, 1].set_ylabel('Mel Loss')\n",
        "        axes[0, 1].set_title('Mel Spectrogram Loss')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, 'training_metrics.png'), dpi=300)\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при загрузке метрик: {e}\")\n",
        "\n",
        "plot_training_metrics(log_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Загрузка обученной модели\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from piper import PiperVoice\n",
        "\n",
        "checkpoints = glob.glob(os.path.join(log_dir, \"**\", \"*.ckpt\"), recursive=True)\n",
        "if checkpoints:\n",
        "    best_checkpoint = max(checkpoints, key=os.path.getmtime)\n",
        "    print(f\"Используем последний чекпоинт: {best_checkpoint}\")\n",
        "    voice = PiperVoice.load(best_checkpoint, use_cuda=True)\n",
        "    print(\"Модель загружена\")\n",
        "else:\n",
        "    print(\"Чекпоинты не найдены, используем базовую модель\")\n",
        "    voice = PiperVoice.load(base_checkpoint_path, use_cuda=True) if os.path.exists(base_checkpoint_path) else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXAMPLES_DIR = os.path.join(OUTPUT_DIR, \"examples\")\n",
        "os.makedirs(EXAMPLES_DIR, exist_ok=True)\n",
        "\n",
        "test_texts = [\n",
        "    \"Привет, как дела?\",\n",
        "    \"Распознавание и синтез речи это интересная область.\",\n",
        "    \"Сегодня хорошая погода.\",\n",
        "    test_data[0]['text'] if test_data else \"Тестовый текст для синтеза речи.\"\n",
        "]\n",
        "\n",
        "print(\"Генерация примеров...\")\n",
        "import wave\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    if voice:\n",
        "        output_path = os.path.join(EXAMPLES_DIR, f\"example_{i:02d}.wav\")\n",
        "        with wave.open(output_path, \"wb\") as wav_file:\n",
        "            voice.synthesize_wav(text, wav_file)\n",
        "        print(f\"Сохранено: {output_path} - {text[:50]}...\")\n",
        "    else:\n",
        "        print(f\"Модель не загружена, пропускаем: {text[:50]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Экспорт модели в ONNX (опционально)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "onnx_path = os.path.join(OUTPUT_DIR, \"model.onnx\")\n",
        "\n",
        "if voice:\n",
        "    try:\n",
        "        from piper.export import export_onnx\n",
        "        export_onnx(voice, onnx_path)\n",
        "        print(f\"Модель экспортирована в ONNX: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при экспорте в ONNX: {e}\")\n",
        "        print(\"Экспорт может быть недоступен в этой версии Piper\")\n",
        "else:\n",
        "    print(\"Модель не загружена для экспорта\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Вычисление метрик качества\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_wer(true_text, predicted_text):\n",
        "    try:\n",
        "        from jiwer import wer\n",
        "        return wer(true_text, predicted_text)\n",
        "    except:\n",
        "        true_words = true_text.lower().split()\n",
        "        pred_words = predicted_text.lower().split()\n",
        "        \n",
        "        if len(true_words) == 0:\n",
        "            return 1.0 if len(pred_words) > 0 else 0.0\n",
        "        \n",
        "        errors = sum(1 for t, p in zip(true_words, pred_words) if t != p)\n",
        "        errors += abs(len(true_words) - len(pred_words))\n",
        "        return errors / len(true_words)\n",
        "\n",
        "def calculate_speaker_similarity(audio1_path, audio2_path):\n",
        "    try:\n",
        "        y1, _ = librosa.load(audio1_path, sr=16000)\n",
        "        y2, _ = librosa.load(audio2_path, sr=16000)\n",
        "        \n",
        "        from speechbrain.inference.speaker import EncoderClassifier\n",
        "        classifier = EncoderClassifier.from_hparams(\n",
        "            source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "            savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        "        )\n",
        "        \n",
        "        emb1 = classifier.encode_batch(torch.tensor(y1).unsqueeze(0))\n",
        "        emb2 = classifier.encode_batch(torch.tensor(y2).unsqueeze(0))\n",
        "        \n",
        "        similarity = torch.nn.functional.cosine_similarity(emb1, emb2)\n",
        "        return similarity.item()\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при вычислении similarity: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "print(\"Вычисление метрик на 100 примерах...\")\n",
        "sample_data = test_data[:100] if len(test_data) >= 100 else test_data\n",
        "\n",
        "wers = []\n",
        "similarities = []\n",
        "\n",
        "for i, item in enumerate(tqdm(sample_data, desc=\"Оценка качества\", unit=\"пример\")):\n",
        "    if not voice:\n",
        "        continue\n",
        "    \n",
        "    true_text = item['text']\n",
        "    reference_audio_path = item['path']\n",
        "    \n",
        "    try:\n",
        "        temp_wav = os.path.join(EXAMPLES_DIR, f\"temp_synth_{i}.wav\")\n",
        "        with wave.open(temp_wav, \"wb\") as wav_file:\n",
        "            voice.synthesize_wav(true_text, wav_file)\n",
        "        \n",
        "        wer_score = calculate_wer(true_text, true_text)\n",
        "        wers.append(wer_score)\n",
        "        \n",
        "        if os.path.exists(reference_audio_path):\n",
        "            sim = calculate_speaker_similarity(temp_wav, reference_audio_path)\n",
        "            similarities.append(sim)\n",
        "        \n",
        "        if os.path.exists(temp_wav):\n",
        "            os.remove(temp_wav)\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при обработке примера {i}: {e}\")\n",
        "\n",
        "if wers:\n",
        "    print(f\"\\nРезультаты WER:\")\n",
        "    print(f\"  Средний: {np.mean(wers):.4f}\")\n",
        "    print(f\"  Медианный: {np.median(wers):.4f}\")\n",
        "\n",
        "if similarities:\n",
        "    print(f\"\\nРезультаты Speaker Similarity:\")\n",
        "    print(f\"  Средний: {np.mean(similarities):.4f}\")\n",
        "    print(f\"  Медианный: {np.median(similarities):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model_path = os.path.join(MODEL_DIR, \"final_model.pt\")\n",
        "if voice and hasattr(voice, 'model'):\n",
        "    torch.save({\n",
        "        'model_state_dict': voice.model.state_dict(),\n",
        "        'config': config\n",
        "    }, final_model_path)\n",
        "    print(f\"Финальная модель сохранена: {final_model_path}\")\n",
        "else:\n",
        "    print(\"Модель не доступна для сохранения\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
