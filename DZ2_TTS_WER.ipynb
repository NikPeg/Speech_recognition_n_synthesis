{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Вычисление WER для TTS модели\n",
        "\n",
        "**Примечание:** WER (Word Error Rate) обычно используется для оценки ASR моделей, но по требованию задания мы вычисляем WER для TTS модели следующим образом:\n",
        "1. Синтезируем аудио из текста через TTS модель\n",
        "2. Распознаем синтезированное аудио через ASR модель (Whisper)\n",
        "3. Сравниваем оригинальный текст с распознанным текстом через WER\n",
        "\n",
        "Это позволяет оценить качество синтеза речи косвенно - если синтезированное аудио распознается с низким WER, значит синтез качественный.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Импорты и настройка\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import wave\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import List, Optional\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(\"✓ Базовые импорты загружены\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Установка зависимостей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка Whisper для ASR (если не установлен)\n",
        "print(\"=\"*60)\n",
        "print(\"УСТАНОВКА И ПРОВЕРКА ЗАВИСИМОСТЕЙ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    import whisper\n",
        "    print(\"✓ Whisper уже установлен\")\n",
        "except ImportError:\n",
        "    print(\"Установка Whisper...\")\n",
        "    %pip install openai-whisper -q\n",
        "    import whisper\n",
        "    print(\"✓ Whisper установлен\")\n",
        "\n",
        "try:\n",
        "    from piper import PiperVoice\n",
        "    print(\"✓ Piper уже установлен\")\n",
        "except ImportError:\n",
        "    print(\"Установка Piper...\")\n",
        "    %pip install piper-tts -q\n",
        "    from piper import PiperVoice\n",
        "    print(\"✓ Piper установлен\")\n",
        "\n",
        "try:\n",
        "    from jiwer import wer\n",
        "    print(\"✓ jiwer уже установлен\")\n",
        "except ImportError:\n",
        "    print(\"Установка jiwer...\")\n",
        "    %pip install jiwer -q\n",
        "    from jiwer import wer\n",
        "    print(\"✓ jiwer установлен\")\n",
        "\n",
        "print(\"\\n✓ Все зависимости готовы\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Поиск TTS модели и конфигурации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ПОИСК TTS МОДЕЛИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Определяем корневую директорию (где находится этот ноутбук)\n",
        "# В Jupyter ноутбуке используем текущую рабочую директорию\n",
        "NOTEBOOK_DIR = os.getcwd()\n",
        "\n",
        "print(f\"Корневая директория: {NOTEBOOK_DIR}\")\n",
        "\n",
        "# Возможные места для поиска модели\n",
        "# ПРИОРИТЕТ: сначала ищем в tts_data (обученная модель), потом в examples (примеры от преподавателя)\n",
        "possible_model_paths = [\n",
        "    # Сначала ищем в tts_data (обученная модель)\n",
        "    os.path.join(NOTEBOOK_DIR, \"tts_data\", \"final_model\", \"final_model.onnx\"),\n",
        "    os.path.join(NOTEBOOK_DIR, \"tts_data\", \"**\", \"*.onnx\"),\n",
        "    # Потом в examples (примеры от преподавателя)\n",
        "    os.path.join(NOTEBOOK_DIR, \"examples\", \"nataha_ruslan.onnx\"),\n",
        "    os.path.join(NOTEBOOK_DIR, \"examples\", \"*.onnx\"),\n",
        "]\n",
        "\n",
        "# Ищем ONNX модель\n",
        "onnx_model_path = None\n",
        "onnx_config_path = None\n",
        "\n",
        "for path_pattern in possible_model_paths:\n",
        "    if '*' in path_pattern:\n",
        "        # Глоб паттерн\n",
        "        matches = glob.glob(path_pattern, recursive=True)\n",
        "        if matches:\n",
        "            # Берем первый найденный\n",
        "            onnx_model_path = matches[0]\n",
        "            print(f\"✓ Найдена модель (glob): {onnx_model_path}\")\n",
        "            break\n",
        "    else:\n",
        "        # Прямой путь\n",
        "        if os.path.exists(path_pattern):\n",
        "            onnx_model_path = path_pattern\n",
        "            print(f\"✓ Найдена модель: {onnx_model_path}\")\n",
        "            break\n",
        "\n",
        "if not onnx_model_path:\n",
        "    print(\"⚠️  ONNX модель не найдена автоматически\")\n",
        "    print(\"\\nПроверяемые пути:\")\n",
        "    for path in possible_model_paths:\n",
        "        exists = \"✓\" if os.path.exists(path) else \"✗\"\n",
        "        print(f\"  {exists} {path}\")\n",
        "    print(\"\\nПожалуйста, укажите путь к модели вручную в следующей ячейке\")\n",
        "else:\n",
        "    # Ищем конфигурационный файл\n",
        "    # ПРИОРИТЕТ: сначала ищем рядом с моделью, потом в tts_data, потом в examples\n",
        "    config_candidates = [\n",
        "        onnx_model_path + \".json\",  # Рядом с моделью\n",
        "        os.path.join(os.path.dirname(onnx_model_path), \"nata_config.json\"),\n",
        "        os.path.join(NOTEBOOK_DIR, \"tts_data\", \"nata_config.json\"),  # В tts_data\n",
        "        os.path.join(NOTEBOOK_DIR, \"examples\", \"nata_config.json\"),  # В examples (примеры)\n",
        "    ]\n",
        "    \n",
        "    for config_path in config_candidates:\n",
        "        if os.path.exists(config_path):\n",
        "            onnx_config_path = config_path\n",
        "            print(f\"✓ Найден конфиг: {onnx_config_path}\")\n",
        "            break\n",
        "    \n",
        "    if not onnx_config_path:\n",
        "        print(\"⚠️  Конфигурационный файл не найден, модель может загрузиться без него\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ЗАГРУЗКА TTS МОДЕЛИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not onnx_model_path:\n",
        "    print(\"⚠️  Модель не найдена. Пожалуйста, укажите путь вручную:\")\n",
        "    print(\"   onnx_model_path = '/path/to/model.onnx'\")\n",
        "    print(\"   onnx_config_path = '/path/to/model.onnx.json'  # опционально\")\n",
        "    voice = None\n",
        "else:\n",
        "    try:\n",
        "        print(f\"Загрузка модели: {onnx_model_path}\")\n",
        "        if onnx_config_path:\n",
        "            print(f\"Использование конфига: {onnx_config_path}\")\n",
        "            voice = PiperVoice.load(onnx_model_path, config_path=onnx_config_path, use_cuda=True)\n",
        "        else:\n",
        "            print(\"Загрузка без конфига...\")\n",
        "            voice = PiperVoice.load(onnx_model_path, use_cuda=True)\n",
        "        print(\"✓ TTS модель успешно загружена\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Ошибка при загрузке модели: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        voice = None\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Инициализация ASR модели (Whisper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ИНИЦИАЛИЗАЦИЯ ASR МОДЕЛИ (WHISPER)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"Загрузка модели Whisper для распознавания...\")\n",
        "try:\n",
        "    asr_model = whisper.load_model(\"base\")  # Используем base для баланса скорости и качества\n",
        "    print(\"✓ Модель Whisper загружена\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Ошибка при загрузке Whisper: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    asr_model = None\n",
        "\n",
        "# Функция для распознавания аудио\n",
        "def transcribe_audio_with_whisper(audio_path: str) -> str:\n",
        "    \"\"\"Распознает аудио через Whisper.\"\"\"\n",
        "    if asr_model is None:\n",
        "        return \"\"\n",
        "    \n",
        "    try:\n",
        "        result = asr_model.transcribe(audio_path, language=\"ru\")\n",
        "        return result[\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при распознавании {audio_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "print(\"\\n✓ ASR модель готова к использованию\")\n",
        "print(f\"\\n{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Подготовка тестовых данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ПОДГОТОВКА ТЕСТОВЫХ ДАННЫХ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Функция для вычисления WER\n",
        "def calculate_wer(true_text: str, predicted_text: str) -> float:\n",
        "    \"\"\"Вычисляет Word Error Rate между двумя текстами.\"\"\"\n",
        "    try:\n",
        "        from jiwer import wer\n",
        "        return wer(true_text, predicted_text)\n",
        "    except:\n",
        "        # Простая реализация, если jiwer не работает\n",
        "        true_words = true_text.lower().split()\n",
        "        pred_words = predicted_text.lower().split()\n",
        "        \n",
        "        if len(true_words) == 0:\n",
        "            return 1.0 if len(pred_words) > 0 else 0.0\n",
        "        \n",
        "        errors = sum(1 for t, p in zip(true_words, pred_words) if t != p)\n",
        "        errors += abs(len(true_words) - len(pred_words))\n",
        "        return errors / len(true_words)\n",
        "\n",
        "# Тестовые тексты для синтеза\n",
        "# Можно заменить на загрузку из файла или использовать свои\n",
        "test_texts = [\n",
        "    \"Привет, как дела?\",\n",
        "    \"Распознавание и синтез речи это интересная область.\",\n",
        "    \"Сегодня хорошая погода.\",\n",
        "    \"Машинное обучение помогает создавать умные системы.\",\n",
        "    \"Нейронные сети используются для обработки естественного языка.\",\n",
        "    \"Технологии искусственного интеллекта развиваются очень быстро.\",\n",
        "    \"Голосовые помощники становятся все более популярными.\",\n",
        "    \"Синтез речи позволяет компьютерам говорить как люди.\",\n",
        "    \"Качество синтеза речи постоянно улучшается.\",\n",
        "    \"Современные модели могут генерировать очень естественную речь.\",\n",
        "]\n",
        "\n",
        "# Пробуем найти тестовые данные из CSV файлов\n",
        "possible_csv_paths = [\n",
        "    os.path.join(NOTEBOOK_DIR, \"tts_data\", \"valid.csv\"),\n",
        "    os.path.join(NOTEBOOK_DIR, \"tts_data\", \"test.csv\"),\n",
        "    os.path.join(NOTEBOOK_DIR, \"**\", \"valid.csv\"),\n",
        "    os.path.join(NOTEBOOK_DIR, \"**\", \"test.csv\"),\n",
        "]\n",
        "\n",
        "csv_data = []\n",
        "csv_path = None\n",
        "\n",
        "for path_pattern in possible_csv_paths:\n",
        "    if '*' in path_pattern:\n",
        "        matches = glob.glob(path_pattern, recursive=True)\n",
        "        if matches:\n",
        "            csv_path = matches[0]\n",
        "            break\n",
        "    else:\n",
        "        if os.path.exists(path_pattern):\n",
        "            csv_path = path_pattern\n",
        "            break\n",
        "\n",
        "if csv_path:\n",
        "    print(f\"✓ Найден CSV файл: {csv_path}\")\n",
        "    print(\"Загрузка данных из CSV...\")\n",
        "    try:\n",
        "        with open(csv_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if '|' in line:\n",
        "                    # Формат: audio_file|text\n",
        "                    parts = line.split('|', 1)\n",
        "                    if len(parts) == 2:\n",
        "                        csv_data.append(parts[1])  # Текст\n",
        "        print(f\"✓ Загружено {len(csv_data)} текстов из CSV\")\n",
        "        if len(csv_data) > 0:\n",
        "            # Используем данные из CSV, ограничиваем до 50 примеров\n",
        "            test_texts = csv_data[:50]\n",
        "            print(f\"Используем {len(test_texts)} примеров из CSV\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Ошибка при чтении CSV: {e}\")\n",
        "        print(\"Используем стандартные тестовые тексты\")\n",
        "else:\n",
        "    print(\"⚠️  CSV файл не найден, используем стандартные тестовые тексты\")\n",
        "    print(f\"Количество тестовых текстов: {len(test_texts)}\")\n",
        "\n",
        "print(f\"\\nИтого тестовых примеров: {len(test_texts)}\")\n",
        "print(f\"\\n{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ВЫЧИСЛЕНИЕ WER ДЛЯ TTS МОДЕЛИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Проверяем, что модели загружены\n",
        "if not voice:\n",
        "    print(\"⚠️  TTS модель не загружена. Невозможно вычислить WER.\")\n",
        "    print(\"   Убедитесь, что модель найдена и загружена в предыдущих ячейках\")\n",
        "elif asr_model is None:\n",
        "    print(\"⚠️  ASR модель не загружена. Невозможно вычислить WER.\")\n",
        "    print(\"   Убедитесь, что Whisper загружен в предыдущих ячейках\")\n",
        "else:\n",
        "    print(\"\\n✓ Обе модели загружены\")\n",
        "    print(f\"Обрабатываем {len(test_texts)} примеров...\")\n",
        "    \n",
        "    wers = []\n",
        "    original_texts = []\n",
        "    recognized_texts = []\n",
        "    processed_count = 0\n",
        "    errors_count = 0\n",
        "    \n",
        "    # Создаем временную директорию для синтезированных аудио\n",
        "    temp_dir = os.path.join(NOTEBOOK_DIR, \"temp_wer_audio\")\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "    \n",
        "    # Обрабатываем примеры\n",
        "    for i, original_text in enumerate(tqdm(test_texts, desc=\"Вычисление WER\", unit=\"пример\")):\n",
        "        try:\n",
        "            if not original_text or not original_text.strip():\n",
        "                errors_count += 1\n",
        "                continue\n",
        "            \n",
        "            # Синтезируем аудио\n",
        "            temp_wav = os.path.join(temp_dir, f\"synth_{i:03d}.wav\")\n",
        "            try:\n",
        "                with wave.open(temp_wav, \"wb\") as wav_file:\n",
        "                    voice.synthesize_wav(original_text, wav_file)\n",
        "                \n",
        "                # Проверяем, что файл создан и не пустой\n",
        "                if not os.path.exists(temp_wav) or os.path.getsize(temp_wav) == 0:\n",
        "                    errors_count += 1\n",
        "                    if errors_count <= 3:\n",
        "                        print(f\"⚠️  Пример {i}: не удалось синтезировать аудио\")\n",
        "                    continue\n",
        "            except Exception as synth_error:\n",
        "                errors_count += 1\n",
        "                if errors_count <= 3:\n",
        "                    print(f\"⚠️  Пример {i}: ошибка синтеза: {synth_error}\")\n",
        "                continue\n",
        "            \n",
        "            # Распознаем синтезированное аудио\n",
        "            recognized_text = transcribe_audio_with_whisper(temp_wav)\n",
        "            \n",
        "            if not recognized_text:\n",
        "                errors_count += 1\n",
        "                if errors_count <= 3:\n",
        "                    print(f\"⚠️  Пример {i}: не удалось распознать аудио\")\n",
        "                continue\n",
        "            \n",
        "            # Вычисляем WER\n",
        "            wer_value = calculate_wer(original_text, recognized_text)\n",
        "            wers.append(wer_value)\n",
        "            original_texts.append(original_text)\n",
        "            recognized_texts.append(recognized_text)\n",
        "            processed_count += 1\n",
        "            \n",
        "            # Выводим первые несколько примеров\n",
        "            if processed_count <= 5:\n",
        "                print(f\"\\nПример {processed_count}:\")\n",
        "                print(f\"  Оригинальный текст: {original_text[:80]}...\")\n",
        "                print(f\"  Распознанный текст: {recognized_text[:80]}...\")\n",
        "                print(f\"  WER: {wer_value:.4f}\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            errors_count += 1\n",
        "            if errors_count <= 3:\n",
        "                import traceback\n",
        "                print(f\"⚠️  Пример {i}: неожиданная ошибка: {e}\")\n",
        "                traceback.print_exc()\n",
        "    \n",
        "    # Очищаем временные файлы\n",
        "    if os.path.exists(temp_dir):\n",
        "        try:\n",
        "            shutil.rmtree(temp_dir)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    # Выводим статистику\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"РЕЗУЛЬТАТЫ ВЫЧИСЛЕНИЯ WER ДЛЯ TTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\nСтатистика обработки:\")\n",
        "    print(f\"  Всего примеров: {len(test_texts)}\")\n",
        "    print(f\"  Успешно обработано: {processed_count}\")\n",
        "    print(f\"  Ошибок: {errors_count}\")\n",
        "    \n",
        "    if wers:\n",
        "        print(f\"\\nWER (Word Error Rate) - чем меньше, тем лучше:\")\n",
        "        print(f\"  Вычислено метрик: {len(wers)}\")\n",
        "        print(f\"  Средний WER: {np.mean(wers):.4f}\")\n",
        "        print(f\"  Медианный WER: {np.median(wers):.4f}\")\n",
        "        print(f\"  Минимальный WER: {np.min(wers):.4f}\")\n",
        "        print(f\"  Максимальный WER: {np.max(wers):.4f}\")\n",
        "        print(f\"  Стандартное отклонение: {np.std(wers):.4f}\")\n",
        "        \n",
        "        # Дополнительная статистика\n",
        "        print(f\"\\nРаспределение WER:\")\n",
        "        print(f\"  WER < 0.1 (отлично): {sum(1 for w in wers if w < 0.1)} ({100*sum(1 for w in wers if w < 0.1)/len(wers):.1f}%)\")\n",
        "        print(f\"  WER < 0.2 (хорошо): {sum(1 for w in wers if w < 0.2)} ({100*sum(1 for w in wers if w < 0.2)/len(wers):.1f}%)\")\n",
        "        print(f\"  WER < 0.3 (удовлетворительно): {sum(1 for w in wers if w < 0.3)} ({100*sum(1 for w in wers if w < 0.3)/len(wers):.1f}%)\")\n",
        "        print(f\"  WER >= 0.3 (требует улучшения): {sum(1 for w in wers if w >= 0.3)} ({100*sum(1 for w in wers if w >= 0.3)/len(wers):.1f}%)\")\n",
        "        \n",
        "        # Показываем примеры с лучшим и худшим WER\n",
        "        if len(wers) > 0:\n",
        "            best_idx = np.argmin(wers)\n",
        "            worst_idx = np.argmax(wers)\n",
        "            \n",
        "            print(f\"\\nЛучший пример (WER = {wers[best_idx]:.4f}):\")\n",
        "            print(f\"  Оригинал: {original_texts[best_idx][:100]}...\")\n",
        "            print(f\"  Распознано: {recognized_texts[best_idx][:100]}...\")\n",
        "            \n",
        "            print(f\"\\nХудший пример (WER = {wers[worst_idx]:.4f}):\")\n",
        "            print(f\"  Оригинал: {original_texts[worst_idx][:100]}...\")\n",
        "            print(f\"  Распознано: {recognized_texts[worst_idx][:100]}...\")\n",
        "        \n",
        "        # Сохраняем результаты в файл\n",
        "        results_file = os.path.join(NOTEBOOK_DIR, \"wer_results.txt\")\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"РЕЗУЛЬТАТЫ ВЫЧИСЛЕНИЯ WER ДЛЯ TTS МОДЕЛИ\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\\n\")\n",
        "            f.write(f\"Модель: {onnx_model_path}\\n\")\n",
        "            f.write(f\"Обработано примеров: {processed_count}\\n\")\n",
        "            f.write(f\"Средний WER: {np.mean(wers):.4f}\\n\")\n",
        "            f.write(f\"Медианный WER: {np.median(wers):.4f}\\n\")\n",
        "            f.write(f\"Минимальный WER: {np.min(wers):.4f}\\n\")\n",
        "            f.write(f\"Максимальный WER: {np.max(wers):.4f}\\n\")\n",
        "            f.write(f\"Стандартное отклонение: {np.std(wers):.4f}\\n\\n\")\n",
        "            f.write(\"Детальные результаты:\\n\")\n",
        "            f.write(\"-\"*60 + \"\\n\")\n",
        "            for i, (orig, rec, wer_val) in enumerate(zip(original_texts, recognized_texts, wers)):\n",
        "                f.write(f\"\\nПример {i+1} (WER = {wer_val:.4f}):\\n\")\n",
        "                f.write(f\"  Оригинал: {orig}\\n\")\n",
        "                f.write(f\"  Распознано: {rec}\\n\")\n",
        "        \n",
        "        print(f\"\\n✓ Результаты сохранены в: {results_file}\")\n",
        "    else:\n",
        "        print(f\"\\n⚠️  Не удалось вычислить WER ни для одного примера.\")\n",
        "        print(f\"   Возможные причины:\")\n",
        "        print(f\"   - Ошибки при синтезе аудио\")\n",
        "        print(f\"   - Ошибки при распознавании аудио\")\n",
        "        print(f\"   - Проблемы с ASR моделью (Whisper)\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
