# Лекция 5: Продвинутый синтез речи (TTS) - Часть 2

## Метрики качества

### Субъективные метрики

**Mean Opinion Score (MOS)** — шкала оценки 1-5

**Критерии:**
- **Naturalness** — естественность/качество
- **Speaker similarity** — похожесть голоса
- **Естественность интонации/соответствие эмоции**

### Объективные метрики

- **Автоматическая оценка MOS:** DNSMOS, UTMOS, NORSEQ
- **Content consistency:** Word/Character Error Rate (WER/CER)
- **Speaker similarity:**
  - Модель кодирования голоса в speaker embedding (ERes2Net, wavlm-base-sv)
  - Косинусная мера близости между векторами референсной и сгенерированной записи
- **Real Time Factor (RTF)** — время генерации 1 секунды аудио

## Эволюция TTS моделей

### LM-based модели

**Подход:** Использование языковых моделей для синтеза речи

## VALL-E (2023)

### Ключевые особенности

- **LM-based подход** — авторегрессионная модель
- **Дискретное представление аудио**
- **Идея из текстовых моделей:** вместо усложнения архитектуры — увеличение модели и размера датасета
  - LibriLight: 60k часов
- **In-context learning** — способность обучаться на контексте
  - Промпт: референсная запись голоса + текст

### Дискретное моделирование в аудио

#### GSLM (Generative Spoken Language Model, 2022)

**Аудио моделирование без текста:**

**Аудио признаки:**
- **Семантика:** HuBERT токены
- **Просодия:** длительности, квантизованные значения F0 (pitch)

**Сценарии:**
- Audio continuation
- Prosody continuation

**Генерация аудио:** Специальная модель HiFi-GAN, обученная на:
- HuBERT токенах
- Квантизованных значениях F0 (pitch)
- Speaker embeddings

#### AudioLM (2022)

**Аудио моделирование без текста:**

**Аудио признаки:**
- **Семантика:** w2v-BERT
- **Акустика:** токенизатор и детокенизатор SoundStream (50Hz, 12 кодбуков)

**Иерархическое предсказание:**
1. **Semantic tokens** — определяют текст
2. **Coarse acoustic tokens** — предсказываются по семантическим токенам (4 первых кода)
   - Глобальная акустическая информация: голос, акустические условия записи
3. **Fine acoustic tokens** — предсказываются по coarse токенам
   - Детальная акустическая информация

**Сценарии:**
- Unconditional generation
- Audio continuation

### Архитектура VALL-E

**Multi-Stream Transformer:**
- **Unit embeddings** (u₀, u₁, ..., uₙ)
- **Delay-1 duration embeddings** (d₋₁, d₀, ..., dₙ)
- **Delay-1 pitch embeddings** (lf₋₁, lf₀, ..., lfₙ)

**Обратные связи:**
- uᵢ → dᵢ₋₁
- dᵢ → lfᵢ₋₁
- lfᵢ → uᵢ

### Conditional Codec Language Modeling

**NAR (Non-Autoregressive) Transformer Decoder:**
- Attend to all tokens одновременно
- Входы: текст (через G2P), аудио (через EnCodec), предыдущие токены
- Выходы: c₀,j, c₁,j, ..., cT,j

**AR (Autoregressive) Transformer Decoder:**
- C₁ attends only to left (только к предыдущим токенам)
- Входы: текст, аудио, предыдущие токены
- Выходы: c₀,₁, c₁,₁, c₂,₁, ..., <EOS>

**Формулы:**
- x = {x₀, x₁, ..., xₗ} — последовательность фонем
- y — аудио для извлечения дискретных токенов

